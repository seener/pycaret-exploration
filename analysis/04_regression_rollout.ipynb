{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "k-pce",
   "display_name": "k-pce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "from pycaret.regression import *\n",
    "import psycopg2 as db\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_build_connection(dbname):\n",
    "    '''A simple function to derive a postgresql connection.\n",
    "\n",
    "    Summary\n",
    "    -------\n",
    "    Create a postgresql connection. This assumes that there is a file\n",
    "    called .sql in the user root folder with database credentials.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    engine: sql engine\n",
    "        A postgresql engine object\n",
    "    '''\n",
    "    # get credentials\n",
    "    root = os.path.expanduser('~')\n",
    "    with open(f'{root}/.sqluser', 'r') as f:\n",
    "        creds = json.load(f)\n",
    "\n",
    "    # build the connection\n",
    "    connection = (f'''postgresql://{creds[\"uid\"]}:{creds[\"pwd\"]}@localhost:5432/{dbname}''')\n",
    "    engine = db.connect(connection)\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_get_data(connection, schema, table, columns='*', where='1=1', query=False):\n",
    "    '''Get sql data into a pandas data frame.\n",
    "\n",
    "    Summary\n",
    "    -------\n",
    "    A flexible function retrieving data from a database into a data frame. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    connection: database connection\n",
    "    schema: string \n",
    "        The schema for the table\n",
    "    table: string\n",
    "        The table name\n",
    "    columns: string\n",
    "        Optional: a comma seperated list of column names\n",
    "    where: string\n",
    "        Optional: a where clause to filter the data\n",
    "    query: string/boolean\n",
    "        Optional: a more complex query with schema.table_name syntax\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: pandas.DataFrame\n",
    "        A pandas data frame\n",
    "    '''\n",
    "    # build the sql query\n",
    "    if query:\n",
    "        sql = query\n",
    "    else:\n",
    "        sql = f'''SELECT {columns} FROM \"{schema}\".\"{table}\" WHERE {where}'''\n",
    "    \n",
    "    # pump it into a data frame\n",
    "    data = pd.read_sql(sql, connection)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_csv_loader(csv_path, target_table, connect):\n",
    "    '''Load csv data into database using pandas and sqlalchemy.\n",
    "\n",
    "    Summary\n",
    "    -------\n",
    "    Take the file path to a csv dataset, load the csv into pandas dataframe, then pipe into database using sqlachemy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path: string\n",
    "        The Fully qualify path to the csv data to be loaded into sql\n",
    "    target_table: mapper\n",
    "        The table object for the target table in the database\n",
    "    conncet: database connection to be used\n",
    "        Database engine to be used\n",
    "    '''\n",
    "    # build the cursor object\n",
    "    cursor = connect.cursor()\n",
    "\n",
    "    # run the data load\n",
    "    truncate = f'''TRUNCATE TABLE {target_table};'''\n",
    "    copy_cmd = f'''COPY {target_table} FROM STDIN WITH (FORMAT CSV, HEADER TRUE, DELIMITER ',');'''\n",
    "    with open(csv_path, 'r') as file_:\n",
    "        cursor.execute(truncate)\n",
    "        cursor.copy_expert(sql=copy_cmd, file=file_)\n",
    "        connect.commit()\n",
    "        cursor.close()\n",
    "    print (f'The data from {csv_path} has been written to {target_table}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### spec ####\n",
    "\n",
    "# Each listed columns will have a model calibrated to predict values for supressed cells\n",
    "mod_col = ['lbf', 'employed', 'employed_full', 'employed_part', 'unemployed', 'not_in_lbf', 'naics_employed', 'naics_goods', 'naics_agriculture', 'naics_natural_resources', 'naics_ultilities', 'naics_construction', 'naics_manufacturing', 'naics_services', 'naics_retail', 'naics_transport_warehousing', 'naics_financial', 'naics_professional', 'naics_support_services', 'naics_education_services', 'naics_health', 'naics_infor_culture', 'naics_accomdation_food', 'naics_other', 'naics_public_admin', 'nocs_employed', 'nocs_management', 'nocs_management_senior', 'nocs_management_specialized', 'nocs_management_retail', 'nocs_management_trades', 'nocs_business', 'nocs_business_pro', 'nocs_business_admin', 'nocs_business_finance', 'nocs_business_office', 'nocs_business_distribution', 'nocs_sciences', 'nocs_sciences_pro', 'nocs_sciences_tech', 'nocs_health', 'nocs_health_nursing', 'nocs_health_pro', 'nocs_health_tech', 'nocs_health_assist', 'nocs_public', 'nocs_public_education', 'nocs_public_pro', 'nocs_public_para', 'nocs_public_protection', 'nocs_public_support', 'nocs_culture', 'nocs_culture_pro', 'nocs_culture_tech', 'nocs_sales', 'nocs_sales_retail', 'nocs_sales_service', 'nocs_sales_wholesale', 'nocs_sales_other', 'nocs_sales_support', 'nocs_sales_nec', 'nocs_trades', 'nocs_trades_industrial', 'nocs_trades_maintenance', 'nocs_trades_other', 'nocs_trades_heavy', 'nocs_trades_helpers', 'nocs_agriculture', 'nocs_agriculture_supervisor', 'nocs_agriculture_workers', 'nocs_agriculture_harvesting', 'nocs_manufacturing', 'nocs_manufacturing_supervisor', 'nocs_manufacturing_operators', 'nocs_manufacturing_assemblers', 'nocs_manufacturing_labourers']\n",
    "\n",
    "# experiment label \n",
    "labl = '_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the count datasets for running imputation process\n",
    "con = sql_build_connection('analytics')\n",
    "cnt_data = sql_get_data(con, 'dev', 'all_imputation_input')\n",
    "\n",
    "# copy of the imputation dataset without t-minus features will be used to store the outputs from the models\n",
    "cols_keep = np.logical_not(cnt_data.columns.str.startswith('tm_'))\n",
    "out_data = cnt_data.loc[:, cols_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load each model generate prediction and save to dataframe\n",
    "for col in mod_col:\n",
    "    model_source = f'../data/{col}{labl}'\n",
    "    model = load_model(model_source, verbose=False)\n",
    "    pred = predict_model(model, data=cnt_data)\n",
    "    out_data[col] = pred['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write versioned table csv\n",
    "date = dt.now().strftime(\"%Y%m%d\")\n",
    "path = os.path.abspath(f'../data/all_imputation_out_{date}.csv')\n",
    "#out_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sql table\n",
    "\n",
    "# sql statements\n",
    "dropper = 'DROP TABLE IF EXISTS dev.all_imputation_result;'\n",
    "creator = f\"CREATE TABLE dev.all_imputation_result AS SELECT id, {(', '.join(mod_col))} FROM dev.all_wide_raw WITH NO DATA;\"\n",
    "\n",
    "# execute sql to create\n",
    "con = sql_build_connection('analytics')\n",
    "cursor = con.cursor()\n",
    "cursor.execute(dropper)\n",
    "cursor.execute(creator)\n",
    "\n",
    "# commit that\n",
    "con.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The data from /Users/sean/Projects/pycaret-exploration/data/all_imputation_out_20200909.csv has been written to dev.all_imputation_result\n"
    }
   ],
   "source": [
    "sql_csv_loader(path, 'dev.all_imputation_result', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load csv into table\n",
    "con.close()"
   ]
  }
 ]
}